{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting ripples from Neuralynx NSC files (2023-01-19 JJS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd; pd.set_option('display.max_columns', 30); pd.set_option('display.max_rows', 100)\n",
    "import numpy as np\n",
    "from ptsa.data.filters import ButterworthFilter, ResampleFilter, MorletWaveletFilter\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from copy import copy\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "import pickle\n",
    "plt.rcParams['pdf.fonttype'] = 42; plt.rcParams['ps.fonttype'] = 42 # fix fonts for Illustrator\n",
    "sys.path.append('/u/home/j/jsakon/johnModules')\n",
    "# new for loading .mat and .edf\n",
    "from scipy import stats,signal,io\n",
    "import time\n",
    "import mat73 # this loads .mat files as dicts\n",
    "from ripple_detection.neuralynx_io import load_ncs\n",
    "import warnings # neuralynx_io gives annoying warnings but seems to work fine\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from ripple_detection.general import *\n",
    "from ripple_detection.slow_wave_ripple import *  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ripple Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, generate macro data using the files in the subject directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 14400512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\"Unable to parse\")\n",
    "path = '../test/data/'\n",
    "\n",
    "# each pair will be subtracted for bipolar referencing\n",
    "\n",
    "\n",
    "fns = [\n",
    "    ['LAH1.ncs','LAH2.ncs'],\n",
    "    ['LA1.ncs','LA2.ncs']\n",
    "    ]\n",
    "\n",
    "macro_mat = []\n",
    "for fn in fns:\n",
    "    macro_ncs1 = load_ncs(path+fn[0])\n",
    "    macro_ncs2 = load_ncs(path+fn[1])\n",
    "    macro_mat = superVstack(macro_mat,macro_ncs1['data']-macro_ncs2['data'])\n",
    "    \n",
    "sr = int(macro_ncs1['header']['SamplingFrequency']) # 2000 for NLX macro\n",
    "\n",
    "np.shape(macro_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize some key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptsa.data.timeseries import TimeSeries\n",
    "import mne\n",
    "from scipy.signal import firwin,filtfilt,kaiserord\n",
    "# import pingouin as pg\n",
    "%autoreload\n",
    "\n",
    "save_values = 0\n",
    "\n",
    "recall_type_switch = 0\n",
    "\n",
    "remove_soz_ictal = 0 # 0 for nothing, 1 for remove SOZ, 2 for keep ONLY SOZ ###\n",
    "\n",
    "min_ripple_rate = 0.1 # Hz. # 0.1 for hamming\n",
    "max_ripple_rate = 1.5 # Hz. # 1.5 for hamming\n",
    "max_trial_by_trial_correlation = 0.05 # if ripples correlated more than this remove them # 0.05 for hamming\n",
    "max_electrode_by_electrode_correlation = 0.2 #??? # 0.2 for hamming\n",
    "\n",
    "filter_type = 'hamming' # see local version below for details \n",
    "desired_sample_rate = 500. # in Hz. This seems like lowerst common denominator recording freq.\n",
    "eeg_buffer = 300 # buffer to add to either end of IRI when processing eeg #**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, preprocess and filter the macro data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn data into PTSA structure\n",
    "time_in_sec = np.linspace(1, np.shape(macro_mat)[1], np.shape(macro_mat)[1]) / sr\n",
    "eeg_ptsa = TimeSeries(np.expand_dims(macro_mat, axis=0), # need event dimension for conversion to MNE later\n",
    "                dims=('event','channel', 'time'),\n",
    "                coords={'event':[0], # so can keep it 3d\n",
    "                        'channel':np.arange(np.shape(macro_mat)[0]),\n",
    "                        'time':time_in_sec,\n",
    "                        'samplerate':sr})\n",
    "\n",
    "# line removal...don't do 120 for now (I never see any line noise there for whatever reason)\n",
    "eeg_ptsa = ButterworthFilter(freq_range=[58.,62.], filt_type='stop', order=4).filter(timeseries=eeg_ptsa)\n",
    "eeg_ptsa = ButterworthFilter(freq_range=[178.,182.], filt_type='stop', order=4).filter(timeseries=eeg_ptsa)\n",
    "\n",
    "\n",
    "# # let's save HFA too\n",
    "# HFA_freqs = np.logspace(np.log10(64),np.log10(178),10)\n",
    "# HFA_eeg = ButterworthFilter(timeseries=eeg_ptsa, freq_range=[118.,122.], filt_type='stop', order=4).filter()\n",
    "# HFA_eeg = ButterworthFilter(timeseries=HFA_eeg, freq_range=0.5, filt_type='highpass',order=4).filter() \n",
    "# HFA_morlet = MorletWaveletFilter(timeseries=HFA_eeg, freqs=HFA_freqs, output='power', width=5, verbose=True).filter()\n",
    "\n",
    "# # # now can remove buffers\n",
    "# # sr_factor = 1000/sr\n",
    "# # HFA_morlet = HFA_morlet[:,:,:,int(eeg_buffer/sr_factor):int(np.shape(HFA_morlet)[3]-(eeg_buffer/sr_factor))]\n",
    "# HFA_morlet = xarray.ufuncs.log10(HFA_morlet, out=HFA_morlet.values) # 10 x events x channels x time\n",
    "# # resample down to 10 Hz (100 ms bins)\n",
    "\n",
    "# HFA_morlet = ResampleFilter(timeseries=HFA_morlet,resamplerate=10).filter() # axes are freqs (10) X words X pairs X bins after downsample\n",
    "# #         # zscore across events & time bins # doing it differently now after talking to Mike 2022-03-08\n",
    "# #         HFA_morlet = (HFA_morlet - np.mean(HFA_morlet, axis=(1,3))) / np.std(HFA_morlet, axis=(1,3)) \n",
    "\n",
    "# # # z-score using std of time bin averaged instead (mean is same either way)\n",
    "# # HFA_morlet = (HFA_morlet - np.mean(HFA_morlet, axis=(1,3))) / np.std(np.mean(HFA_morlet, axis=3),axis=1)\n",
    "# # HFA_morlet = np.mean(HFA_morlet,0) # mean over the 10 frequencies (now down to events X pairs X 100 ms bins)\n",
    "\n",
    "# # without events I think we just average over time (axis 2)\n",
    "# HFA_morlet = (HFA_morlet - np.mean(HFA_morlet, axis=2)) / np.std(np.mean(HFA_morlet, axis=2),axis=1)\n",
    "# HFA_morlet = np.mean(HFA_morlet,0) # mean over the 10 frequencies (now down to events X pairs X 100 ms bins)\n",
    "\n",
    "\n",
    "\n",
    "## FILTERS ##\n",
    "trans_width = 5. # Width of transition region, normalized so that 1 corresponds to pi radians/sample. \n",
    "# That is, the frequency is expressed as a fraction of the Nyquist frequency.\n",
    "ntaps = (2/3)*np.log10(1/(10*(1e-3*1e-4)))*(sr/trans_width) # gives 400 with sr=500, trans=5\n",
    "# formula from Belanger's Digital Processing of Signals\n",
    "# see https://dsp.stackexchange.com/questions/31066/how-many-taps-does-an-fir-filter-need for how to use\n",
    "\n",
    "# if sr == 512 or sr == 1024 or sr == 1023.999: # last one fixes R1221P @@\n",
    "#     ntaps = np.ceil(ntaps)\n",
    "nyquist = sr/2        \n",
    "\n",
    "# filter for ripples using filter selected above\n",
    "if filter_type == 'hamming':\n",
    "    # need to subtract out to get the filtered signal since default is bandstop but want to keep it as PTSA  \n",
    "    FIR_bandstop = firwin(int(ntaps+1), [70.,178.], fs=sr, window='hamming',pass_zero='bandstop')               \n",
    "    #         eeg_rip_band = filtfilt(FIR_bandpass,1.,eeg_ptsa) # can't use ptsa_to_mne this way so use eeg minus bandstopped signal            \n",
    "    eeg_rip_band = eeg_ptsa-filtfilt(FIR_bandstop,1.,eeg_ptsa) \n",
    "    bandstop_25_60 = firwin(int(ntaps+1), [20.,58.], fs=sr, window='hamming',pass_zero='bandstop') # Norman 2019 IED            \n",
    "    eeg_ied_band = eeg_ptsa-filtfilt(bandstop_25_60,1.,eeg_ptsa)\n",
    "    ntaps40, beta40 = kaiserord(40, trans_width/nyquist)\n",
    "    kaiser_40lp_filter = firwin(ntaps40, cutoff=40, window=('kaiser', beta40), scale=False, nyq=nyquist, pass_zero='lowpass')            \n",
    "elif filter_type == 'butter':\n",
    "    eeg_rip_band = ButterworthFilter(timeseries=eeg_ptsa, freq_range=[80.,120.], filt_type='bandpass',order=2).filter()\n",
    "    eeg_ied_band = ButterworthFilter(timeseries=eeg_ptsa, freq_range=[250.,490.], filt_type='bandpass',order=2).filter() #^^^\n",
    "    time_length = np.shape(eeg_rip_band)[2]/int(sr/1000)\n",
    "    eeg_raw = ptsa_to_mne(eeg_ptsa,[0,time_length]) #[0,psth_end-psth_start+2*eeg_buffer])    #**  \n",
    "#         eeg_ptsa = None # clear variable # no reason to do this in local version...really for cluster\n",
    "elif filter_type == 'staresina':\n",
    "    FIR_bandstop_star = firwin(241, [80.,100.], fs=sr, window='hamming',pass_zero='bandstop') # order = 3*80+1               \n",
    "    eeg_rip_band = eeg_ptsa-filtfilt(FIR_bandstop_star,1.,eeg_ptsa)\n",
    "\n",
    "if filter_type is not 'staresina':\n",
    "    time_length = np.shape(eeg_rip_band)[2]/int(sr/1000)\n",
    "    eeg_rip_band = ptsa_to_mne(eeg_rip_band,[0,time_length]) #[0,psth_end-psth_start+2*eeg_buffer]) #** \n",
    "    _ = eeg_rip_band.apply_hilbert(envelope=True)\n",
    "    eeg_ied_band = ptsa_to_mne(eeg_ied_band,[0,time_length]) #[0,psth_end-psth_start+2*eeg_buffer]) #** \n",
    "    _ = eeg_ied_band.apply_hilbert(envelope=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, construct the ripple array. This will contain the exact times of the ripple onsets as boolean values of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel #0 of 2\n",
      "skipped b/c 0.056664651923487165 below ripple rate thresh 0.1 for channel: 0\n",
      "Channel #1 of 2\n",
      "skipped b/c 0.06013675069330868 below ripple rate thresh 0.1 for channel: 1\n"
     ]
    }
   ],
   "source": [
    "ripple_array = []\n",
    "HFA_array = []\n",
    "\n",
    "trial_by_trial_correlation = []\n",
    "elec_by_elec_correlation = []\n",
    "elec_ripple_rate_array = []\n",
    "    \n",
    "session_ripple_rate_by_elec = []\n",
    "\n",
    "total_channel_ct = 0\n",
    "\n",
    "for channel in range(np.shape(eeg_rip_band.get_data())[1]): # unpack number of channels\n",
    "    print(f'Channel #{channel} of {np.shape(eeg_rip_band.get_data())[1]}')\n",
    "    total_channel_ct+=1 # total channels before artifact removal\n",
    "    \n",
    "    if filter_type != 'staresina':\n",
    "        # get data from MNE container \n",
    "        eeg_rip = eeg_rip_band.get_data()[:,channel,:]     \n",
    "        eeg_ied = eeg_ied_band.get_data()[:,channel,:]\n",
    "    else:\n",
    "        eeg_rip = eeg_rip_band[:,channel,:] # filtered signal still in PTSA format\n",
    "\n",
    "    # select detection algorithm (note that iedlogic is same for both so always run that)\n",
    "    if filter_type == 'hamming':\n",
    "        # filter IEDs \n",
    "        eeg_ied = eeg_ied**2 # already rectified now square\n",
    "        eeg_ied = filtfilt(kaiser_40lp_filter,1.,eeg_ied) # low pass filter  \n",
    "        mean1 = np.mean(eeg_ied)\n",
    "        std1 = np.std(eeg_ied)\n",
    "        iedlogic = eeg_ied>=mean1+4*std1 # Norman et al 2019            \n",
    "        # detect ripples\n",
    "        ripplelogic = detect_ripples_hamming(eeg_rip,trans_width,sr,iedlogic)\n",
    "    elif filter_type == 'butter':\n",
    "        eeg_mne = eeg_raw.get_data()[:,channel,:]\n",
    "        # detect ripples\n",
    "        ripplelogic, iedlogic = detect_ripples_butter(eeg_rip,eeg_ied,eeg_mne,sr)    \n",
    "    elif filter_type == 'staresina':\n",
    "        ripplelogic = detect_ripples_staresina(eeg_rip, sr)\n",
    "\n",
    "    if filter_type == 'butter': # ^^^\n",
    "        desired_sample_rate = 1000 # for Vaz algo\n",
    "\n",
    "    if sr>desired_sample_rate: # downsampling here for anything greater than 500 (hamming) or 1000 (butter)\n",
    "        ripplelogic = downsampleBinary(ripplelogic,sr/desired_sample_rate)\n",
    "        \n",
    "    # ripples are detected, so can remove buffers now #\n",
    "\n",
    "    # if ripplelogic is just 1d (because it only has 1 \"trial\") it bugs out programs below\n",
    "    if len(ripplelogic.shape) == 1: # if just detecting within a single vector\n",
    "        ripplelogic = np.expand_dims(ripplelogic,axis=0)\n",
    "\n",
    "    # skip this electrode if the ripple rate is below threshold\n",
    "    temp_start_array,_ = getStartEndArrays(ripplelogic)\n",
    "    elec_ripple_rate = np.sum(temp_start_array)/temp_start_array.shape[0]/(time_length/1000)\n",
    "    \n",
    "    if elec_ripple_rate < min_ripple_rate:\n",
    "        print(f'skipped b/c {elec_ripple_rate} below ripple rate thresh {min_ripple_rate} for channel: {channel}')\n",
    "        continue\n",
    "    elif elec_ripple_rate > max_ripple_rate:\n",
    "        print(f'skipped b/c {elec_ripple_rate} above ripple rate thresh {min_ripple_rate} for channel: {channel}')\n",
    "        continue # skip this electrode\n",
    "\n",
    "    # check the ripples for this electrode and make sure they're not super correlated across trials\n",
    "\n",
    "    # first, bin the array so can get more realistic correlation not dependent on ms timing\n",
    "    \n",
    "    binned_ripplelogic = downsampleBinary(ripplelogic[:, :ripplelogic.size - ripplelogic.size%10],10) # downsample by 10x so 10 ms bins\n",
    "    trial_ripple_df = pd.DataFrame(data=np.transpose(binned_ripplelogic))\n",
    "    num_cols = len(list(trial_ripple_df))\n",
    "    temp_tbt_corr = 0\n",
    "    if num_cols > 1: # if more than 1 trial\n",
    "        trial_ripple_df.columns = ['col_' + str(i) for i in range(num_cols)] # generate range of ints for suffixes\n",
    "        if sum(sum(trial_ripple_df))>1:\n",
    "            temp_tbt_corr = np.mean(pg.pairwise_corr(trial_ripple_df,method='spearman').r)\n",
    "        else:\n",
    "            temp_tbt_corr = 1    \n",
    "        if temp_tbt_corr > max_trial_by_trial_correlation:\n",
    "            print('skipped b/c above trial-by-trial correlation for ch.: '+str(channel))\n",
    "            continue\n",
    "\n",
    "    ## if this electrode passes SAVE data ##\n",
    "    trial_by_trial_correlation.append(temp_tbt_corr) # corr b/w trials\n",
    "    elec_ripple_rate_array.append(elec_ripple_rate) # record the average ripple rate for this electrode\n",
    "\n",
    "    # append arrays across electrodes\n",
    "    ripple_array = superVstack(ripple_array,ripplelogic) # append across electrodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get start times for ripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_start_array.shape\n",
    "elec_ripple_rate\n",
    "np.sum(temp_start_array)/temp_start_array.shape[0]/(time_length/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_array,end_array = getStartEndArrays(ripple_array) # get start array\n",
    " \n",
    "print('Got start_array with '+str(start_array.shape[0])+' trials!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(start_array)\n",
    "np.sum(start_array,1)\n",
    "np.sum(start_array,1)[0]/(np.shape(start_array)[1]/desired_sample_rate) # 500 Hz sampling\n",
    "np.sum(start_array,1)[1]/(np.shape(start_array)[1]/desired_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot raster\n",
    "plt.subplots(1,1,figsize=(20,2))   \n",
    "plt.scatter(np.where(start_array)[1]/1000,np.where(start_array)[0],s=4,color='k') # SWR time v. trial\n",
    "plt.xlabel('Time from recall (s)')\n",
    "plt.ylabel('Channel')\n",
    "ax = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
